{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b629d018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost\n",
    "import shap\n",
    "import RDG_interventional_classification\n",
    "import RDG_gaussian_classification\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb95fd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.classification.kernel_based import RocketClassifier\n",
    "from sktime.datasets import load_gunpoint\n",
    "from sktime.datasets import load_italy_power_demand\n",
    "\n",
    "X, y = load_italy_power_demand()\n",
    "\n",
    "\n",
    "numpy_X = []\n",
    "for i in range(0,X.shape[0]):\n",
    "    numpy_X.append(X.loc[i].values[0])\n",
    "X = np.asarray(numpy_X)\n",
    "\n",
    "y = np.asarray(y)\n",
    "\n",
    "X = (X - np.min(X))/(np.max(X)-np.min(X))\n",
    "#y =  (y - np.min(y))/(np.max(y)-np.min(y))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "025f9adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.29590033, 0.21276607, 0.17951236, ..., 0.52313396, 0.45108427,\n",
       "        0.3734923 ],\n",
       "       [0.246229  , 0.16995674, 0.14303712, ..., 0.54234481, 0.41223332,\n",
       "        0.35390748],\n",
       "       [0.6527679 , 0.5210177 , 0.45514259, ..., 0.83392445, 0.81745567,\n",
       "        0.70217424],\n",
       "       ...,\n",
       "       [0.19880741, 0.16591476, 0.15358004, ..., 0.56473789, 0.47017158,\n",
       "        0.39616317],\n",
       "       [0.54643376, 0.53143661, 0.44145372, ..., 0.84637674, 0.80138529,\n",
       "        0.75639384],\n",
       "       [0.31847259, 0.22192337, 0.15755724, ..., 0.54911795, 0.45793257,\n",
       "        0.42038565]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb474583",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = np.arange(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bcbd4925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '1', '2', ..., '2', '2', '2'], dtype='<U1')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51c13b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = RocketClassifier(num_kernels=100)\n",
    "reg.fit(np.asarray(X_train), np.asarray(y_train))\n",
    "clf = reg\n",
    "clf.predict_proba(X_test[3].reshape(1,24))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c4d3a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-16 11:33:37.179653: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-03-16 11:33:37.179768: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2023-03-16 11:33:37.312678: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-03-16 11:33:37.506051: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 61ms/step\n",
      "63/91 [===================>..........] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-16 11:33:55.109585: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9779005524861878"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sktime.classification.deep_learning.cnn import CNNClassifier\n",
    "cnn = CNNClassifier(n_epochs=20,batch_size=4,verbose=False)  \n",
    "cnn.fit(X_train, y_train)\n",
    "cnn.predict_proba(X_test[0].reshape(1,-1))[0][0]\n",
    "cnn.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "94f198b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7876e78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cov = np.cov(X.T)\n",
    "means = X.mean(axis=0)\n",
    "\n",
    "minis = np.min(X,axis=0)\n",
    "maxis = np.max(X,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "182aded1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "import random\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22afcfe9",
   "metadata": {},
   "source": [
    "ground_truth = {}\n",
    "for i in range(0,len(clf.coef_[0])):\n",
    "    ground_truth[i] = np.abs(clf.coef_[0][i])\n",
    "sorted_indexes = sorted(ground_truth, key=ground_truth.get,reverse=True)\n",
    "sorted_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a541f8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The start time is : 405062.387580583\n",
      "1/1 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80faf901b24b47b5a309242bd043aec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 9ms/step\n",
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n",
      "524/524 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "524/524 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "524/524 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "  1/524 [..............................] - ETA: 7s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "  1/524 [..............................] - ETA: 12s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "524/524 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "  1/524 [..............................] - ETA: 12s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "  1/524 [..............................] - ETA: 10s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "524/524 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "  1/524 [..............................] - ETA: 12s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "  1/524 [..............................] - ETA: 7s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "  1/524 [..............................] - ETA: 7s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "  1/524 [..............................] - ETA: 8s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "  1/524 [..............................] - ETA: 6s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n",
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "  1/524 [..............................] - ETA: 6s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "  1/524 [..............................] - ETA: 8s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "  1/524 [..............................] - ETA: 7s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "  1/524 [..............................] - ETA: 6s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "  1/524 [..............................] - ETA: 9s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "  1/524 [..............................] - ETA: 10s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "  1/524 [..............................] - ETA: 6s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "  1/524 [..............................] - ETA: 9s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "  6/524 [..............................] - ETA: 5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "  1/524 [..............................] - ETA: 6s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "  1/524 [..............................] - ETA: 7s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "  1/524 [..............................] - ETA: 7s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "  1/524 [..............................] - ETA: 8s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "  1/524 [..............................] - ETA: 5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 153ms/step\n",
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "  1/524 [..............................] - ETA: 8s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 45ms/step\n",
      "524/524 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "524/524 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "524/524 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 82ms/step\n",
      "524/524 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "524/524 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "524/524 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "  1/524 [..............................] - ETA: 7s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "  1/524 [..............................] - ETA: 7s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "  1/524 [..............................] - ETA: 10s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "  1/524 [..............................] - ETA: 11s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 2ms/step\n",
      "The time difference is : 131.96310166700277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    }
   ],
   "source": [
    "starttime = timeit.default_timer()\n",
    "print(\"The start time is :\",starttime)\n",
    "e = shap.KernelExplainer(clf.predict_proba,means.reshape(1,-1))\n",
    "ks_shap_values = e.shap_values(X_test[0:100])[0]\n",
    "print(\"The time difference is :\", timeit.default_timer() - starttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8a001c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.003985207661463071"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ks_shap_values[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c493a881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The start time is : 406280.202072416\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "in here\n",
      "\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "117/184 [==================>...........] - ETA: 0s"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [68]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#int_seps,int_nonseps = RDG_interventional_classification.RDG_separate(clf.predict_proba,x,means,minis,maxis,0.2)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m100\u001b[39m):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m#ss_i_atts= RDG_interventional_classification.atts_separate(clf.predict_proba,x,means,minis,maxis,0.2,int_seps,int_nonseps)\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     ss_g_atts \u001b[38;5;241m=\u001b[39m \u001b[43mRDG_gaussian_classification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43matts_separate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmeans\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcov\u001b[49m\u001b[43m,\u001b[49m\u001b[43mminis\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmaxis\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcond_seps\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcond_nonseps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe time difference is :\u001b[39m\u001b[38;5;124m\"\u001b[39m, timeit\u001b[38;5;241m.\u001b[39mdefault_timer() \u001b[38;5;241m-\u001b[39m starttime)\n",
      "File \u001b[0;32m~/Downloads/phd/projects/compromise/shapley_sets/shapley_sets/RDG_gaussian_classification.py:433\u001b[0m, in \u001b[0;36matts_separate\u001b[0;34m(f, x, means, cov, mini, maxi, e, X, seps, nonseps)\u001b[0m\n\u001b[1;32m    430\u001b[0m \t\t\t\u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[1;32m    431\u001b[0m \t\t\t\ttemp\u001b[38;5;241m.\u001b[39mappend(temp_bounds[i])\n\u001b[0;32m--> 433\u001b[0m \t\t\tatts[\u001b[38;5;28mtuple\u001b[39m(var)] \u001b[38;5;241m=\u001b[39m f(np\u001b[38;5;241m.\u001b[39masarray(temp)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m nonseps:\n\u001b[1;32m    436\u001b[0m \tS \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/sktime/classification/base.py:262\u001b[0m, in \u001b[0;36mBaseClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_single_class_y_pred(X, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_proba\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# call internal _predict_proba\u001b[39;00m\n\u001b[0;32m--> 262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/sktime/classification/deep_learning/base.py:106\u001b[0m, in \u001b[0;36mBaseDeepClassifier._predict_proba\u001b[0;34m(self, X, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# Transpose to work correctly with keras\u001b[39;00m\n\u001b[1;32m    105\u001b[0m X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mtranspose((\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m--> 106\u001b[0m probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# check if binary classification\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m probs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;66;03m# first column is probability of class 0 and second is of class 1\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/keras/engine/training.py:2031\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2029\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, iterator \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39menumerate_epochs():  \u001b[38;5;66;03m# Single epoch.\u001b[39;00m\n\u001b[1;32m   2030\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[0;32m-> 2031\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[1;32m   2032\u001b[0m       callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_begin(step)\n\u001b[1;32m   2033\u001b[0m       tmp_batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_function(iterator)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/keras/engine/data_adapter.py:1248\u001b[0m, in \u001b[0;36mDataHandler.steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n\u001b[1;32m   1247\u001b[0m   \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1248\u001b[0m original_spe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m   1249\u001b[0m can_run_full_execution \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1250\u001b[0m     original_spe \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1251\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m\n\u001b[1;32m   1253\u001b[0m     original_spe)\n\u001b[1;32m   1255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_run_full_execution:\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/tensorflow/python/ops/resource_variable_ops.py:637\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnumpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    636\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    638\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    639\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1159\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \n\u001b[1;32m   1138\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1156\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1159\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1125\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1124\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1126\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "starttime = timeit.default_timer()\n",
    "print(\"The start time is :\",starttime)\n",
    "cond_seps,cond_nonseps = RDG_gaussian_classification.RDG_separate(clf.predict_proba,x,means,cov,minis,maxis,0.2,X_train)\n",
    "#int_seps,int_nonseps = RDG_interventional_classification.RDG_separate(clf.predict_proba,x,means,minis,maxis,0.2)\n",
    "for a in range(0,100):\n",
    "    #ss_i_atts= RDG_interventional_classification.atts_separate(clf.predict_proba,x,means,minis,maxis,0.2,int_seps,int_nonseps)\n",
    "    ss_g_atts = RDG_gaussian_classification.atts_separate(clf.predict_proba,x,means,cov,minis,maxis,0.2,X_train,cond_seps,cond_nonseps)\n",
    "print(\"The time difference is :\", timeit.default_timer() - starttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1ed06d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [63]\u001b[0m, in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#tree_scores = []\u001b[39;00m\n\u001b[1;32m     20\u001b[0m x \u001b[38;5;241m=\u001b[39m X_test[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 21\u001b[0m cond_seps,cond_nonseps \u001b[38;5;241m=\u001b[39m \u001b[43mRDG_gaussian_classification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRDG_separate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmeans\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcov\u001b[49m\u001b[43m,\u001b[49m\u001b[43mminis\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmaxis\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m int_seps,int_nonseps \u001b[38;5;241m=\u001b[39m RDG_interventional_classification\u001b[38;5;241m.\u001b[39mRDG_separate(clf\u001b[38;5;241m.\u001b[39mpredict_proba,x,means,minis,maxis,\u001b[38;5;241m0.2\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(int_nonseps)\n",
      "File \u001b[0;32m~/Downloads/phd/projects/compromise/shapley_sets/shapley_sets/RDG_gaussian_classification.py:361\u001b[0m, in \u001b[0;36mRDG_separate\u001b[0;34m(f, x, means, cov, mini, maxi, e, X)\u001b[0m\n\u001b[1;32m    359\u001b[0m comparison \u001b[38;5;241m=\u001b[39m X2\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(X2) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 361\u001b[0m \tX1_star \u001b[38;5;241m=\u001b[39m \u001b[43minteract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmeans\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcov\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmini\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmaxi\u001b[49m\u001b[43m,\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    363\u001b[0m \t\u001b[38;5;28;01mif\u001b[39;00m X1_star \u001b[38;5;241m==\u001b[39m X1:\n\u001b[1;32m    364\u001b[0m \t\t\u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(X1) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/Downloads/phd/projects/compromise/shapley_sets/shapley_sets/RDG_gaussian_classification.py:165\u001b[0m, in \u001b[0;36minteract\u001b[0;34m(f, X1, X2, x, means, cov, mini, maxi, e, X)\u001b[0m\n\u001b[1;32m    163\u001b[0m tempX2 \u001b[38;5;241m=\u001b[39m X1\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    164\u001b[0m X11 \u001b[38;5;241m=\u001b[39m interact(f,tempX2,G1,x,means,cov,mini,maxi,e,X)\n\u001b[0;32m--> 165\u001b[0m X21 \u001b[38;5;241m=\u001b[39m \u001b[43minteract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtempX1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mG2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmeans\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcov\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmaxi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmaxi\u001b[49m\u001b[43m,\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m X1 \u001b[38;5;241m=\u001b[39m []\t\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m X11:\n",
      "File \u001b[0;32m~/Downloads/phd/projects/compromise/shapley_sets/shapley_sets/RDG_gaussian_classification.py:164\u001b[0m, in \u001b[0;36minteract\u001b[0;34m(f, X1, X2, x, means, cov, mini, maxi, e, X)\u001b[0m\n\u001b[1;32m    162\u001b[0m tempX1 \u001b[38;5;241m=\u001b[39m X1\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    163\u001b[0m tempX2 \u001b[38;5;241m=\u001b[39m X1\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m--> 164\u001b[0m X11 \u001b[38;5;241m=\u001b[39m \u001b[43minteract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtempX2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mG1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmeans\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcov\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmini\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmaxi\u001b[49m\u001b[43m,\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m X21 \u001b[38;5;241m=\u001b[39m interact(f,tempX1,G2,x,means,cov,maxi,maxi,e,X)\n\u001b[1;32m    166\u001b[0m X1 \u001b[38;5;241m=\u001b[39m []\t\n",
      "File \u001b[0;32m~/Downloads/phd/projects/compromise/shapley_sets/shapley_sets/RDG_gaussian_classification.py:111\u001b[0m, in \u001b[0;36minteract\u001b[0;34m(f, X1, X2, x, means, cov, mini, maxi, e, X)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[1;32m    109\u001b[0m \ttemp\u001b[38;5;241m.\u001b[39mappend(temp_bounds[i])\n\u001b[0;32m--> 111\u001b[0m new_prediction \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    113\u001b[0m sigma_1 \u001b[38;5;241m=\u001b[39m original_prediction \u001b[38;5;241m-\u001b[39m new_prediction\n\u001b[1;32m    116\u001b[0m original_prediction \u001b[38;5;241m=\u001b[39m f(np\u001b[38;5;241m.\u001b[39masarray(means)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/sktime/classification/base.py:262\u001b[0m, in \u001b[0;36mBaseClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_single_class_y_pred(X, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_proba\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# call internal _predict_proba\u001b[39;00m\n\u001b[0;32m--> 262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/sktime/classification/deep_learning/base.py:106\u001b[0m, in \u001b[0;36mBaseDeepClassifier._predict_proba\u001b[0;34m(self, X, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# Transpose to work correctly with keras\u001b[39;00m\n\u001b[1;32m    105\u001b[0m X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mtranspose((\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m--> 106\u001b[0m probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# check if binary classification\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m probs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;66;03m# first column is probability of class 0 and second is of class 1\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/keras/engine/training.py:2002\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1995\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m   1996\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1997\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUsing Model.predict with MultiWorkerMirroredStrategy or \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1998\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTPUStrategy and AutoShardPolicy.FILE might lead to out-of-order \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1999\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult. Consider setting it to AutoShardPolicy.DATA.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   2000\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m-> 2002\u001b[0m data_handler \u001b[38;5;241m=\u001b[39m \u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2003\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2004\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2005\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2006\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2007\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2008\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2009\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2010\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2011\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2012\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2014\u001b[0m \u001b[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[1;32m   2015\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/keras/engine/data_adapter.py:1401\u001b[0m, in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cluster_coordinator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1400\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1401\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataHandler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/keras/engine/data_adapter.py:1151\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1148\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution \u001b[38;5;241m=\u001b[39m steps_per_execution\n\u001b[1;32m   1150\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m select_data_adapter(x, y)\n\u001b[0;32m-> 1151\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter \u001b[38;5;241m=\u001b[39m \u001b[43madapter_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1157\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribution_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1165\u001b[0m strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n\u001b[1;32m   1167\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/keras/engine/data_adapter.py:328\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m flat_dataset\n\u001b[1;32m    326\u001b[0m indices_dataset \u001b[38;5;241m=\u001b[39m indices_dataset\u001b[38;5;241m.\u001b[39mflat_map(slice_batch_indices)\n\u001b[0;32m--> 328\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mslice_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    331\u001b[0m   \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshuffle_batch\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch):\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/keras/engine/data_adapter.py:360\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.slice_inputs\u001b[0;34m(self, indices_dataset, inputs)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrab_batch\u001b[39m(i, data):\n\u001b[1;32m    358\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(\u001b[38;5;28;01mlambda\u001b[39;00m d: tf\u001b[38;5;241m.\u001b[39mgather(d, i, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), data)\n\u001b[0;32m--> 360\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrab_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAUTOTUNE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;66;03m# Default optimizations are disabled to avoid the overhead of (unnecessary)\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;66;03m# input pipeline graph serialization and deserialization\u001b[39;00m\n\u001b[1;32m    365\u001b[0m options \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mOptions()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:2050\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2048\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m MapDataset(\u001b[38;5;28mself\u001b[39m, map_func, preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m   2049\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2050\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mParallelMapDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2051\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2052\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpreserve_cardinality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2056\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:5284\u001b[0m, in \u001b[0;36mParallelMapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m   5282\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_dataset \u001b[38;5;241m=\u001b[39m input_dataset\n\u001b[1;32m   5283\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_inter_op_parallelism \u001b[38;5;241m=\u001b[39m use_inter_op_parallelism\n\u001b[0;32m-> 5284\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5285\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5286\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5288\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_legacy_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_legacy_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5290\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deterministic \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:271\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    265\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    266\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    267\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    268\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    269\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m--> 271\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m    273\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2567\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2558\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   2559\u001b[0m   \u001b[38;5;124;03m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[1;32m   2560\u001b[0m \n\u001b[1;32m   2561\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2565\u001b[0m \u001b[38;5;124;03m       or `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[1;32m   2566\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2567\u001b[0m   graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2568\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2569\u001b[0m   graph_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   2570\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2533\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2531\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2532\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m-> 2533\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2534\u001b[0m   seen_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m   2535\u001b[0m   captured \u001b[38;5;241m=\u001b[39m object_identity\u001b[38;5;241m.\u001b[39mObjectIdentitySet(\n\u001b[1;32m   2536\u001b[0m       graph_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39minternal_captures)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2711\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2708\u001b[0m   cache_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mgeneralize(cache_key)\n\u001b[1;32m   2709\u001b[0m   (args, kwargs) \u001b[38;5;241m=\u001b[39m cache_key\u001b[38;5;241m.\u001b[39m_placeholder_value()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m-> 2711\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2712\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39madd(cache_key, cache_key_deletion_observer,\n\u001b[1;32m   2713\u001b[0m                          graph_function)\n\u001b[1;32m   2715\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2627\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2622\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   2623\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m   2624\u001b[0m ]\n\u001b[1;32m   2625\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[1;32m   2626\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[0;32m-> 2627\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2628\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2629\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2630\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2631\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2632\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2635\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2636\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   2637\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[1;32m   2638\u001b[0m     spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[1;32m   2639\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m   2640\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m   2641\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m   2642\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m   2643\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   2644\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1038\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(op_return_value, ops\u001b[38;5;241m.\u001b[39mTensor), op_return_value\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m   func_graph \u001b[38;5;241m=\u001b[39m \u001b[43mFuncGraph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollections\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapture_by_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_graph, FuncGraph)\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m add_control_dependencies:\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:196\u001b[0m, in \u001b[0;36mFuncGraph.__init__\u001b[0;34m(self, name, collections, capture_by_value, structured_input_signature, structured_outputs)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    168\u001b[0m              name,\n\u001b[1;32m    169\u001b[0m              collections\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    170\u001b[0m              capture_by_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    171\u001b[0m              structured_input_signature\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    172\u001b[0m              structured_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    173\u001b[0m   \u001b[38;5;124;03m\"\"\"Construct a new FuncGraph.\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \n\u001b[1;32m    175\u001b[0m \u001b[38;5;124;03m  The graph will inherit its graph key, collections, seed, and distribution\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;124;03m      information.\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m   \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mFuncGraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m    198\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minputs \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:3113\u001b[0m, in \u001b[0;36mGraph.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3111\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_functions \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mOrderedDict()\n\u001b[1;32m   3112\u001b[0m \u001b[38;5;66;03m# Default GraphDef versions\u001b[39;00m\n\u001b[0;32m-> 3113\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_def_versions \u001b[38;5;241m=\u001b[39m \u001b[43mversions_pb2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVersionDef\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproducer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mversions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGRAPH_DEF_VERSION\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_consumer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mversions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGRAPH_DEF_VERSION_MIN_CONSUMER\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3116\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_building_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   3117\u001b[0m \u001b[38;5;66;03m# Stack of colocate_with ops. In TF2.x or after switch_to_thread_local(),\u001b[39;00m\n\u001b[1;32m   3118\u001b[0m \u001b[38;5;66;03m# self._thread_local._colocation_stack is used instead.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/google/protobuf/internal/python_message.py:516\u001b[0m, in \u001b[0;36m_AddInitMethod.<locals>.init\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_listener_for_children \u001b[38;5;241m=\u001b[39m _Listener(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m field_name, field_value \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 516\u001b[0m   field \u001b[38;5;241m=\u001b[39m \u001b[43m_GetFieldByName\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_descriptor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfield_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    517\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m field \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m() got an unexpected keyword argument \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m    519\u001b[0m                     (message_descriptor\u001b[38;5;241m.\u001b[39mname, field_name))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "overall_ss_g_sum_indexes = []\n",
    "overall_ss_i_sum_indexes = []\n",
    "overall_ks_sum_indexes = []\n",
    "\n",
    "overall_tree_sum_indexes = []\n",
    "\n",
    "\n",
    "overall_ss_g_indexes = []\n",
    "overall_ss_i_indexes = []\n",
    "overall_ks_indexes = []\n",
    "\n",
    "overall_tree_indexes = []\n",
    "\n",
    "ss_g_scores = []\n",
    "ss_i_scores = []\n",
    "ks_scores = []\n",
    "og_scores = []\n",
    "#tree_scores = []\n",
    "\n",
    "x = X_test[0]\n",
    "\n",
    "cond_seps,cond_nonseps = RDG_gaussian_classification.RDG_separate(clf.predict_proba,x,means,cov,minis,maxis,0.2,X_train)\n",
    "int_seps,int_nonseps = RDG_interventional_classification.RDG_separate(clf.predict_proba,x,means,minis,maxis,0.2)\n",
    "\n",
    "print(int_nonseps)\n",
    "print(cond_nonseps)\n",
    "for a in range(0,100):\n",
    "    x = X_test[a]\n",
    "    ss_i_atts= RDG_interventional_classification.atts_separate(clf.predict_proba,x,means,minis,maxis,0.2,int_seps,int_nonseps)\n",
    "    ss_g_atts = RDG_gaussian_classification.atts_separate(clf.predict_proba,x,means,cov,minis,maxis,0.2,X_train,cond_seps,cond_nonseps)\n",
    "    \n",
    "    ks_atts = {}\n",
    "    for val in range(0,len(ks_shap_values[a])):\n",
    "        ks_atts[val] = ks_shap_values[a][val]\n",
    "    \n",
    "        \n",
    "    #tree_atts = {}\n",
    "    #for val in range(0,len(tree_shap_values[a])):\n",
    "        #tree_atts[val] = tree_shap_values[a][val]\n",
    "\n",
    "    print(ks_atts)\n",
    "    temp = {}\n",
    "    for u in ss_i_atts.keys():\n",
    "        temp[u] = np.abs(ss_i_atts[u])\n",
    "    sorted_ss_i_indexes = sorted(temp, key=temp.get, reverse=True)\n",
    "    \n",
    "    temp = {}\n",
    "    for u in ss_g_atts.keys():\n",
    "        temp[u] = np.abs(ss_g_atts[u]) \n",
    "    sorted_ss_g_indexes = sorted(temp, key=temp.get, reverse=True)\n",
    "    \n",
    "    temp = {}\n",
    "    for u in list(ks_atts.keys()):\n",
    "        temp[u] = np.abs(ks_atts[u]) \n",
    "    print(temp)\n",
    "    sorted_ks_indexes = sorted(temp, key=temp.get, reverse=True)\n",
    "    \n",
    "    \n",
    "    #temp = {}\n",
    "    #for u in tree_atts.keys():\n",
    "       # temp[u] = np.abs(tree_atts[u]) \n",
    "    #sorted_tree_indexes = sorted(temp, key=temp.get, reverse=True)\n",
    "    \n",
    "    overall_ss_g_indexes.append(sorted_ss_g_indexes[0])\n",
    "    overall_ss_i_indexes.append(sorted_ss_i_indexes[0])\n",
    "    overall_ks_indexes.append(sorted_ks_indexes[0])\n",
    "    #overall_og_indexes.append(sorted_og_indexes[0])\n",
    "    #overall_tree_indexes.append(sorted_tree_indexes[0])\n",
    "    \n",
    "    total_sum = clf.predict_proba(x.reshape(1,-1))[0][0] -  clf.predict_proba(means.reshape(1,-1))[0][0]\n",
    "\n",
    "    overall_ss_i_sum_indexes.append(sum(ss_i_atts.values()) - total_sum)\n",
    "    overall_ss_g_sum_indexes.append(sum(ss_g_atts.values()) - total_sum)\n",
    "    overall_ks_sum_indexes.append(sum(ks_atts.values()) - total_sum)\n",
    "    #overall_og_sum_indexes.append(sum(og_atts.values()) - total_sum)\n",
    "    \n",
    "    \n",
    "    ind = sorted_ss_g_indexes[0]\n",
    "    new_x = x.copy()\n",
    "    if len(list(ind)) > 1:\n",
    "        for u in list(ind):\n",
    "            new_x[u] = means[u]\n",
    "    else:\n",
    "        new_x[list(ind)[0]] = means[list(ind)[0]]\n",
    "    \n",
    "    prediction = clf.predict_proba(new_x.reshape(1,-1))[0][0]\n",
    "    \n",
    "    ss_g_scores.append(np.abs(prediction - clf.predict_proba(means.reshape(1,-1))[0][0]))\n",
    "    \n",
    "    ind = sorted_ss_i_indexes[0]\n",
    "    new_x = x.copy()\n",
    "    if len(list(ind)) > 1:\n",
    "        for u in list(ind):\n",
    "            new_x[u] = means[u]\n",
    "    else:\n",
    "        new_x[list(ind)[0]] = means[list(ind)[0]]\n",
    "    \n",
    "    prediction = clf.predict_proba(new_x.reshape(1,-1))[0][0]\n",
    "    \n",
    "    ss_i_scores.append(np.abs(prediction - clf.predict_proba(means.reshape(1,-1))[0][0]))\n",
    "    \n",
    "    ind = sorted_ks_indexes[0]\n",
    "    new_x = x.copy()\n",
    "    \n",
    "    new_x[ind] = means[ind]\n",
    "    \n",
    "    prediction = clf.predict_proba(new_x.reshape(1,-1))[0][0]\n",
    "    \n",
    "    ks_scores.append(np.abs(prediction - clf.predict_proba(means.reshape(1,-1))[0][0]))\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \"\"\"ind = sorted_tree_indexes[0]\n",
    "    new_x = x.copy()\n",
    "    \n",
    "    new_x[ind] = means[ind]\n",
    "    \n",
    "    prediction = clf.predict(new_x.reshape(1,-1))\n",
    "    \n",
    "    tree_scores.append(np.abs(prediction - clf.predict(means.reshape(1,-1))))\"\"\"\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6ab29cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[14, 18]]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_nonseps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "df367deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[14, 19, 18, 15, 20]]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_nonseps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a5c158db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interventional\n",
      "sum\n",
      "0.004840260744094849\n",
      "0.64449381669918\n",
      "faithfulness\n",
      "0.30765635\n",
      "0.1491617\n",
      "gaussian conditional\n",
      "sum\n",
      "1.335070538520813\n",
      "0.43981036755959446\n",
      "faithfulness\n",
      "0.28235883\n",
      "0.11725261\n",
      "KS\n",
      "sum\n",
      "-1.5832483768463134e-09\n",
      "6.317223564576961e-09\n",
      "faithfulness\n",
      "0.2876753\n",
      "0.16471417\n",
      " \n",
      "ATTS:\n",
      "\n",
      "KS\n",
      "{0: 0.05101852404964218, 1: 0.04061233497548319, 2: 0.013090895360083081, 3: -0.0017449360389549342, 4: -0.0006500484832217173, 5: -0.008674608003350237, 6: 0.0058374302551692904, 7: 0.03498975637003759, 8: 0.02938268393372665, 9: 0.004169182502268005, 10: -0.003243449468640718, 11: 0.000911670484924413, 12: 0.007894246305085588, 13: -0.07603828821021745, 14: -0.11413842470221638, 15: -0.08753753372422594, 16: -0.022156653881694726, 17: 0.15029460725863053, 18: 0.2370831540301282, 19: 0.06059166593282947, 20: -0.036830975915244056, 21: -0.047438870739261986, 22: -0.003925073248831866, 23: 0.024335893769588834}\n",
      "I\n",
      "{(0,): 0.06637895, (1,): 0.05669439, (2,): 0.02102822, (3,): -0.0015932322, (4,): -0.0013313293, (5,): -0.013005972, (6,): 0.009981573, (7,): 0.050938547, (8,): 0.042234957, (9,): 0.006905794, (10,): -0.0053055882, (11,): 0.00046902895, (12,): 0.011521339, (13,): -0.111177325, (15,): -0.11240402, (16,): -0.020851552, (17,): 0.17074329, (19,): 0.078930736, (20,): -0.05102086, (21,): -0.07380134, (22,): -0.0025947094, (23,): 0.038585782, (14, 18): 0.14281428}\n",
      "G\n",
      "{(0,): 0.13332766, (1,): 0.12362349, (2,): 0.08795017, (3,): 0.06532776, (4,): 0.06558865, (5,): 0.05391407, (6,): 0.076901734, (7,): 0.117872, (8,): 0.1091544, (9,): 0.07382041, (10,): 0.061613023, (11,): 0.06738913, (12,): 0.07844162, (13,): -0.044259608, (16,): 0.04604751, (17,): 0.23766756, (21,): -0.006903112, (22,): 0.06437379, (23,): 0.10553807, (14, 19, 18, 15, 20): 0.13593626}\n"
     ]
    }
   ],
   "source": [
    "print('interventional')\n",
    "print('sum')\n",
    "print(np.mean(overall_ss_i_sum_indexes))\n",
    "print(np.std(overall_ss_i_sum_indexes))\n",
    "\n",
    "print('faithfulness')\n",
    "print(np.mean(ss_i_scores))\n",
    "print(np.std(ss_i_scores))\n",
    "\n",
    "print('gaussian conditional')\n",
    "\n",
    "print('sum')\n",
    "print(np.mean(overall_ss_g_sum_indexes))\n",
    "print(np.std(overall_ss_g_sum_indexes))\n",
    "\n",
    "print('faithfulness')\n",
    "print(np.mean(ss_g_scores))\n",
    "print(np.std(ss_g_scores))\n",
    "\n",
    "print('KS')\n",
    "\n",
    "print('sum')\n",
    "print(np.mean(overall_ks_sum_indexes))\n",
    "print(np.std(overall_ks_sum_indexes))\n",
    "\n",
    "print('faithfulness')\n",
    "print(np.mean(ks_scores))\n",
    "print(np.std(ks_scores))\n",
    "\n",
    "\n",
    "print(\" \")\n",
    "print(\"ATTS:\")\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"KS\")\n",
    "\n",
    "print(ks_atts)\n",
    "\n",
    "print(\"I\")\n",
    "\n",
    "print(ss_i_atts)\n",
    "\n",
    "print(\"G\")\n",
    "\n",
    "print(ss_g_atts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b883be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(clf.predict_proba(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "49921798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(13, 19, 20, 14, 17, 18)]\n",
      "[(20,)]\n",
      "[19]\n"
     ]
    }
   ],
   "source": [
    "print(overall_ss_g_indexes)\n",
    "print(overall_ss_i_indexes)\n",
    "print(overall_ks_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f72f361e",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_x = x.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d6d14095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.32555546, 0.25364814, 0.16735937, 0.11702425, 0.10983352,\n",
       "       0.14578718, 0.20331304, 0.34712765, 0.44779788, 0.6131847 ,\n",
       "       0.63475689, 0.64913836, 0.6131847 , 0.48375154, 0.44779788,\n",
       "       0.4046535 , 0.43341642, 0.44060715, 0.50532373, 0.57004031,\n",
       "       0.59161251, 0.62756615, 0.53408666, 0.43341642])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e203d382",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [43]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots()\n\u001b[1;32m      2\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m24\u001b[39m)\n\u001b[1;32m      4\u001b[0m ax\u001b[38;5;241m.\u001b[39mplot(x, selected_x, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblack\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "x = np.arange(0, 24)\n",
    "\n",
    "ax.plot(x, selected_x, color='black')\n",
    "ax.plot(x, means, color='blue')\n",
    "\n",
    "#threshold = 0.1\n",
    "#ax.axhline(threshold, color='green', lw=2, alpha=0.7)\n",
    "ax.axvspan(18, 23, alpha=0.5, color='red')\n",
    "\n",
    "ax.axvspan(0, 4, alpha=0.5, color='green')\n",
    "\n",
    "ax.axvspan(12, 16, alpha=0.5, color='green')\n",
    "ax.set_ylabel('Power Demand')\n",
    "ax.set_xlabel('Hour of Day')\n",
    "plt.axvline(x=18,color='black')\n",
    "plt.savefig('time_series_2.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02707cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict_proba(X_test[100].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7652b7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict_proba(means.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0902498e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
