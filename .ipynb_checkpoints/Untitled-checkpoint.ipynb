{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d187cbe",
   "metadata": {},
   "source": [
    "#### Feature Grouping\n",
    "\n",
    "First of all would like to thank the reviewer for their very thorough comments and questions, really appreciate the time you put into engaging with the paper. \n",
    "\n",
    "The feature grouping techniques suggested by the reviewer [1,2,3], all consider take into account the interaction in the data to then partition the features into groups, after which the Shapley value is then calculated. All these approaches differ from our approach in the following ways. \n",
    "\n",
    "First and foremorst, Shapley Sets is capable of uncovering interaction in the model as well as in the data. This is the significant advantage of our approach compared to the other feature grouping strategies suggested. For example, consider the situation (X1,X2,X3,X4) where (X1,X2) are all correlated. Under a grouping generated by correlated clustering, for example, the Shapley value would be calculated for (X1,X2),(X3),(X4). However, Shapley sets, under v_{marg} would return the grouping (X1),(X2),(X3,X4) and under v_{cond} would return the grouping (X1,X2),(X3,X4) offerring more insight into the \\textbf{true} feature groupings than the groupings solely based on interaction between features in the data. \n",
    "\n",
    "Secondly, Shapley Sets is designed to find the optimal grouping of the features such that the Shapley value theoretically reduces to the simple computation of v(X_{i}) where X_{i} is the group of features represented by an individual NSVG. Therefore, the grouping under Shapley Sets requires linear time to compute (given the prior decomposition of the variable set under log linear time), whereas the grouping proposed under the Grouped Shapley value still requires (2^{k}) computations (to compute exactly), where k is the number of groupings although this can be approximated. \n",
    "\n",
    "[1] https://github.com/slundberg/shap/blob/master/shap/utils/_legacy.py#L144\n",
    "\n",
    "[2] https://github.com/slundberg/shap/blob/45b85c1837283fdaeed7440ec6365a886af4a333/shap/maskers/_tabular.py#L33\n",
    "\n",
    "[3] Jullum et al., \"groupShapley: Efficient prediction explanation with Shapley values for feature groups\" (2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfb3959",
   "metadata": {},
   "source": [
    "#### When Everything Interacts\n",
    "\n",
    "While it is true that Shapley Sets only generates meaningful attributions for partially separable functions we explicitly state this in the paper. Furthermore, it is well known that the Shapley value itself also relies on this assumption. As shown in [1]:\n",
    "\n",
    "\"Under an interventional interpretation, Shapley values are as\n",
    "uninformative for non-additive models as this alternative attribution (a non additive attribution) is for linear ones. For instance, any value function which always evaluates to 0 except on the grand coalition\n",
    "will evenly distribute influence among players regardless of individual feature values\" \n",
    "\n",
    "In this example, Shapley Sets would group all features together to award a joint attribuion. We can thus view the resulting Shapley Sets attribution in this case as a warning not to use either Shapley Sets or the Shapley value to explain a model prediction. \n",
    "\n",
    "->\"it is not clear whether the idea of learning tidy feature groups is meaningful beyond toy examples like those in the experiments section\"\n",
    " \n",
    "We have shown on three Benchmark datasets that the attribution under Shapley Sets generates improved attributions (under our metrics which we validate below) than Shapley value alternatives. We have also discussed the qualitative advantages of the groupings generated by Shapley Sets on the time series case study. However, to further show that we have not just cherry picked this example we will include the following quantiative results for three time series datasets: the Italy Power Demand, Gun Point and Basic Motions, all taken from the SKTime library. Each dataset is trained with a CNN model as specified in the original paper. Average Deletion is calculated over each attribution for all the individual samples in each dataset and results are shown in the table below. Shapley Sets obtains the lowest deletion scores across all three datasets, further motivating the meaningful attributions generated by our attribution approach.\n",
    "\n",
    "\n",
    "|               \t| KS                 \t| SS Cond            \t| SS Int             \t|\n",
    "|---------------\t|--------------------\t|--------------------\t|--------------------\t|\n",
    "| Italy PD      \t| $0.414 \\pm 0.175$  \t| $0.377 \\pm 0.178$  \t| $0.415 \\pm 0.157$  \t|\n",
    "| Basic Motions \t| $0.126 \\pm 0.100$  \t| $0.118 \\pm 0.113$  \t| $0.016 \\pm 0.008$  \t|\n",
    "| Gun Point     \t| $0.280 \\pm  0.141$ \t| $0.011 \\pm  0.005$ \t| $0.250 \\pm 0.0927$ \t|\n",
    "\n",
    "While we agree that simply selecting a metric and using it to justify the \"goodness\" of an attribution method is not ideal we believe that comparably to other work in this space, our experimental evaluation is extensive. Furthermore, the theoretical novelity of Shapley Sets is compelling in itself and will provide the basis for future work into experimentally validating the grouped attributions it generates in practice. \n",
    "\n",
    "[1] Kumar, I. Elizabeth, et al. \"Problems with Shapley-value-based explanations as feature importance measures.\" International Conference on Machine Learning. PMLR, 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114bab15",
   "metadata": {},
   "source": [
    "#### Additively Separable Function and Modularity\n",
    "\n",
    "The idea of decomposing the partially separable function into its non-interacting components (NSVG's) using the entire domain of the feature set is one of the main beneifts of our approach in that it unifies local and global attributions as the NSVGs are constant for every possible candidate over the domain of $X$. If we were to limit the partition of the variable set to match the following definition of functional modularity rather than separability:  \n",
    "\n",
    "\"functional modularity requires a partition setting to be optimal for some set of contexts (complement of the partition) and compared to some set of comparison settings (candidate vectors x over the domain of $X$)\" [1]\n",
    "\n",
    "such that we determined the interaction structure for a single comparison setting (candidate vector) $x$. Then this local,global consistency may no longer hold. I.e. the feature interaction structure determined for one candidate vector may differ to another despite these structures being fixed over the entire domain.\n",
    "\n",
    "We note that the above discussion applies to Shapley Sets in theory. In practice, the search for NSVGs over the domain of $X$ is approxmated with randomly selected candidate vectors within the Shapley Sets algorithm. We therefore thank the reviewer for pointing us in the direction of modularity and will explore the connection more thoroughly in future work. \n",
    "\n",
    "[1] De Jong, E. D., Thierens, D., & Watson, R. A. (2004, June). Defining modularity, hierarchy, and repetition. \n",
    "\n",
    "[2] Sun, Y., Kirley, M., and Halgamuge, S. K. A recursive de-composition method for large scale continuous optimization. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edf3ef0",
   "metadata": {},
   "source": [
    "#### Misc Math\n",
    "\n",
    "-> Example 2:\n",
    "\n",
    "We will include the statement 'E[X2]=E[X1]=E[X3] = 0' and 'x=(1,1,1)'\n",
    "\n",
    "-> NSVG definition\n",
    "\n",
    "We amend the NSVG definition to the following\n",
    "\n",
    "Let $\\mathbf{X} = \\{X_{1},X_{2},...X_{n}\\}$ be the set of decision variables. Let $\\mathbf{X}_{i}$ be a subset of decision variables $\\mathbf{X}_{i} \\subseteq \\mathbf{X}$. Given a partially separable function $f : \\mathbb{R}^{n} \\rightarrow \\mathbb{R}$, if there exists any two candidate vectors $\\mathbf{x} = \\{x_{1},...,x_{n}\\}$ and $\\mathbf{x}' = \\{x'_{1},...,x'_{n}\\}$ which are sampled from the domain of $\\mathbf{X}$ such that the following property holds for  any two mutually exclusive subsets $\\mathbf{X}_{i},\\mathbf{X}_{j} \\subset \\mathbf{X}$ such that $\\mathbf{X}_{i} \\cap \\mathbf{X}_{j} = \\varnothing$,\n",
    "\n",
    "\\begin{equation}\n",
    "\\label{eq_interaction}\n",
    "f(\\mathbf{x})_{\\mathbf{X}_{i} \\cup \\mathbf{X}_{j}} - f(\\mathbf{x})_{\\mathbf{X}_{j}}\n",
    "\\not = f(\\mathbf{x})_{\\mathbf{X}_{i}} - f(\\mathbf{x})_{\\mathbf{X}_{\\varnothing}}\n",
    "\\end{equation}\n",
    "\n",
    "where $f(\\mathbf{x})_{\\mathbf{X}_{S}} = f(\\mathbf{X}_{S} = \\mathbf{x}_{S}, \\mathbf{X}_{\\bar{S}} = \\mathbf{x'}_{\\bar{S}})$ and $\\mathbf{X}_{S} \\cup \\mathbf{X}_{\\bar{S}} = \\mathbf{X}$. Then the sets $\\mathbf{X}_{i},\\mathbf{X}_{j}$ are said to interact (For a full proof, see [1]). If $|\\mathbf{X}_{i}|$ and $|\\mathbf{X}_{j}|$ is minimized such that the above condition still holds then $\\mathbf{X}_{i} \\cup \\mathbf{X}_{j}$ is a NSVG.\n",
    "\n",
    "\n",
    "-> Missing Subtraction\n",
    "\n",
    "No both are correct here as our definition of the value function in Equations 3 and 4 include the subtraction of the value of the empty set. Thus, when substituting in the value functions in Equations 6 and 7, $f(\\mathbf{x})_{\\mathbf{X}_{\\varnothing}}$ is alrady included in the right hand term.\n",
    "\n",
    "-> Additional assumption of non-interaction between the NSVGs.\n",
    "\n",
    "We state (line) that the formed variable group must satisfy Definition 2.1 as well as Definition 1.2 with regards to the specified value function. The example of (X1,X2) (X3,X4) due to correlation between groups will not satisfy Definition 1.2 and therefore is not the ideal grouping which is assumed for Proposition 2.2. Therefore no further assumption of the NSVG is necessary. \n",
    "\n",
    "[1] Sun, Y., Kirley, M., and Halgamuge, S. K. A recursive de-composition method for large scale continuous optimiza-\n",
    "tion. IEEE Transactions on Evolutionary Computation, 22(5):647–661, 2017."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc41d23",
   "metadata": {},
   "source": [
    "#### Related Work \n",
    "\n",
    "-> The authors write that the marginal approach to handling held-out features was formalized by Janzing et al. and that the baseline approach was introduced by Sundararajan & Najmi. In fact, both appear in Lundberg & Lee (2017).\n",
    "\tWe have included the reference to [1] in both instances\n",
    "\n",
    "-> Use of Dummy \n",
    "\tChanged the \"Violation of Dummy\" to \"Violation of Sensitivity\" which is in line with [2]\n",
    "\n",
    "-> KernelSHAP\n",
    "We include this line, \"The original implementation of KS [1] is an approximation of off-manifold Shap however later variants of KS [3] adapted it to be used with on-manifold value functions\"\n",
    "\n",
    "[1] Lundberg, S. M. and Lee, S.-I. A unified approach to interpreting model predictions.\n",
    "[2] Janzing, D., Minorics, L., and Bl  ̈obaum, P. Feature rele-vance quantification in explainable ai: A Causal Problem\n",
    "[3] Aas, K., Jullum, M., and Løland, A. Explaining individual predictions when features are dependent: More accurate approximations to shapley values. Artificial Intelligence,298:103502, 2021.\n",
    "\n",
    "#### Notation \n",
    "\n",
    "-> The coalitional game notation used throughout the paper is an odd choice\n",
    "\n",
    "\n",
    " We amend the definition of value functions to $v(\\mathbf{x},S)$ to help readability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda0baad",
   "metadata": {},
   "source": [
    "#### Synthetic Experiments\n",
    "\n",
    "As has been noted in the majority of work in this space, evaluating feature attributions is difficult and relies on proxies. We believe that our synthetic experiments are considered and validate theoretical claims made in the paper. We also evaluate our approach on three tabular datasets and three time series datasets which is considerably more than most of the approahces in this space. \n",
    "\n",
    "-> I'm not sure if evaluating the regular Shapley value here is fair. If possible, the authors might put more focus on why their ground truth/method is more useful here.\n",
    "\n",
    "The comparison between the ground truth groupings and the Shapley value in this context has previously been made by [1] and we feel we are justified in showing how the Shapley Sets algorithm is capable of extracting these interactions where the Shapley value is not. We show how this grouped attribution in the context of feature interaction in the model is particularly advantageous for inverse relationships between features. This inverse relationshop \\textbf{is} included in the synthetic experiments, just as $\\frac{X1}{2 + X4}$ rather than $\\frac{X1}{1 - X2}$ which displays the same beahviour as each feature is sampled from $(-1,1)$.\n",
    "\n",
    "We will also include the following example of when our grouped attributions are more useful: \n",
    "Consider the function $f(\\mathbf{X}) = X1 + (X2 \\cap X3)$ with the binary variable set $\\{X_{1},X_{2},X_{3}$. Given the example to explain $x=(1,1,1)$ and reference $z=(0,0,0)$, the Shapley value under $v_{bs}$ would split the attribution of $(X2 \\cap X3)$ evenly between X2 and X3. A user may now expect that changing X2 would change the outcome. However, $f(1,0,1)$ is still $0$. This information is captured by the Shapley Sets grouped attribution which, when used to attribute both instances $(1,0,1)$ and $(1,1,1)$ would tell the user that $X2,X3$ interact as well as offer insight into the kind of relationship between them.  \n",
    "\n",
    "-> why the linear model coefficients should be used as the ground truth.\n",
    "\n",
    "We follow the approach of [2] (specifically Theorem 1) where \"permutation importance methods return the squared coefficient of the corresponding covariate, multiplied by the covariate’s marginal sum of squares. When the covariates are standardized, this results in associating variable importance with the magnitude of the corresponding\n",
    "coefficient, approximately corresponding to common interpretations in linear models.\"\n",
    "\n",
    "\n",
    "[1] Shapley residuals: Quantifying the limits of the shapley value for explanations.\n",
    "[2] Hooker, G., Mentch, L., & Zhou, S. (2021). Unrestricted permutation forces extrapolation: variable importance requires at least one more model, or there is no free variable importance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fde9a68",
   "metadata": {},
   "source": [
    "#### Benchmark Experiments\n",
    "\n",
    "-> Metrics \n",
    "\n",
    "We amend Equations 10 and 11 to the follwoing:\n",
    "\n",
    "$AD = \\frac{1}{k} \\sum_{j=1}^{k} |v(\\mathbf{x}_{j},\\varnothing) - v(\\mathbf{x}_{j},N \\backslash \\{i\\})|$\n",
    "\n",
    "$AS = \\frac{1}{k} \\sum_{j=1}^{k} |v(\\mathbf{x}_{j},N) - \\sum_{i = 1}^{n} m(\\textbf{X}_{ij})|$\n",
    " \n",
    "And correct the following line generating the confusion surrounding sensitivity:\n",
    "\n",
    "'We therefore also assess the sensitivity of the attribution technique which calculates the difference between the sum of all the attributions given by the attribution technique and the total change in prediction between the sample and reference value.' \n",
    "\n",
    "to \n",
    "\n",
    "'We therefore also assess the sensitivity of the attribution technique which calculates the difference between the sum of all the attributions given by the attribution technique and the prediction of the sample'\n",
    "\n",
    "-> Justification of Deletion and Sensitivity:\n",
    "\n",
    "Deletion: We know that $f(\\mathbf{x}) = m(X_{1}) + m(X_{2} + ... + m(X_{n}) + m(X_{\\varnothing})$ [1],\n",
    "therefore as we remove features from $\\mathbf{x}$ we move closer to the baseline, or \"target\" prediction. We chose to use Deletion as a measure of whether the removal of the most important feature moved the prediction \\textbf{in the right direction} towards the target prediction rather than the Faithfulness:\n",
    "\n",
    "$v(\\mathbf{x}_{j},N) - v(\\mathbf{x}_{j},N \\backslash \\{i\\})|$\n",
    "\n",
    "which measures just the change in prediction.\n",
    "\n",
    "Sensitivity: This measures the extent to which the approximation of the Shapley value is efficient and has been used in []. We believe this is a useful measure to include for Shapley Sets where an incorrect grouping would result in a high sensitivity score. This metric is therefore particularly useful to validate Shapley Sets on real world data. \n",
    "\n",
    "Our time series example motivates a use-case of the groupings generated by Shapley Sets. Using a qualitative example to demonstrate the kind of attribution offered by a technique is common practice. To show we are not cherry picking and to extend the experimental results to non-benchmark datasets we show the faithfulness achieved on this dataset as a further experiement\n",
    "\n",
    "[1] Kumar, I. Elizabeth, et al. \"Problems with Shapley-value-based explanations as feature importance measures.\" International Conference on Machine Learning. PMLR, 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc382f0b",
   "metadata": {},
   "source": [
    "####  Computational Weakness Discussion\n",
    "\n",
    "We will include the following disucssion and table in the paper:\n",
    "\n",
    "One of the benefits of the Shapley Sets algorithm is that it computes the decomposition of the underlying function globally such that all NSGVs are constant for every possible candidiate vector $\\mathbf{x}$ over the domain of $\\mathbf{X}$. Pratcically, this means that the computation of Shapley Sets only needs to be run once for a dataset. Once the NSVGs have been identified, each attribution vector can be computed trivially for local instances as $v(\\mathbf{x},\\mathbf{X}_{i})$. This is an advantage over KernelSHAP where attributions for multiple instances require the computation of the Shapley value for each instance. The Table below shows the runtime (in seconds) for Shapley Sets Conditional, Shapley Sets Interventional, KernelSHAP with 1 background sample and for 10 background samples (both KernelSHAP variants intialised with otherwise default parameters). The runtime shows how long it took to compute each local attribution for each sample across three time series datasets: Italy Power Demand, Basic Motions and GunPoint, all taken from the SKtime library. From the Table we can see that although KernelSHAP with one background sample is the quickest algorithm, it scales poorly as we extent the number of background samples from 1 to 10. Both the Shapley Sets variants offer a comparable performance although the computational cost of computing $v_{cond}$ is evident. Future work would look at reducing the computational burden of the conditional expectation and would compare Shapley Sets on other high dimensional datatypes such as images. \n",
    "\n",
    "\n",
    "|               \t| Samples \t| Time Steps \t| KS (1 background) \t| KS (10 background) \t| SS Cond \t| SS Int \t|\n",
    "|---------------\t|---------\t|------------\t|------------------\t|-------------------\t|---------\t|--------\t|\n",
    "| Italy PD      \t| 100     \t| 24         \t| 131              \t| 936               \t| 280    \t| 127    \t|\n",
    "| Basic Motions \t| 80      \t| 100        \t| 141              \t| 880               \t|475     \t| 200   \t|\n",
    "| Gun Point     \t| 200     \t| 150        \t| 400              \t| 2400              \t| 1030   \t| 503   \t|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e826c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reviewer 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54232e9",
   "metadata": {},
   "source": [
    "#### Interaction Indexes \n",
    "\n",
    "The following will be added to the paper under Related Work\n",
    "\n",
    "The attributions under the Shapley-Taylor interaction indices capture information about how the players\n",
    "in S interact with each other individually. For example if for a certain game\n",
    "$v({a}) + v({b}) = v({a, b})$, this means that the term v({a, b}) provides no interaction information\n",
    "about the two players, and Ik{i,j} for explanation sizes k > 2 will be 0. However, the Shapley-Taylor interactions do not consider interaction between sets of players. For example, given that\n",
    "$v({a}) + v({c}) = v({a, c})$ and $v({a}) + v({b}) = v({a, b})$, under Shapley-Tayloy, a and b will not be considered to interact with c despite the following holding $v({a, b, c}) - v({b, c}) \\not = v({a, c}) - v({c})$\n",
    "\n",
    "In contrast, under the ideal decomposition of $f$ into its NSVGs, if $\\mathbf{X}_{i} = \\{c\\}$ and $\\mathbf{X}_{j} = \\{a,b\\}$, then the sets $\\mathbf{X}_{j}$ and $\\mathbf{X}_{i}$ would be joined into an NSVG, capturing this conditional interaction. In practice, this kind of interaction is captured by Algorithm 2 (specifically the line: if X′1 is the same as X1 then). Thus, Shapley Sets is capable of capturing conditional interaction where Shapley Taylor interaction indexes are not. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d62873",
   "metadata": {},
   "source": [
    "\n",
    "#### Interactability in Algorithm (1) seems to be defined over a single marginal value, whereas to my understanding - the expectation should be taken over different coalitions for a proper assesment of interaction. The authors are encouraged to correct me on this.\n",
    "\n",
    "While the theoretical definition of an NSVG depends on the evaluation of every single candidate decision vector $\\mathbf{x}$ from the domain of $\\mathbf{X}$, within the function decomposition literature, including the original RDG algorithm upon which the Shapley Sets algorithm was based, it is enough to approximate the above with a single randomly chosen decision vector upon which to determine the interaction between sets of variables. In practice, this works well (as shown by Table 1 and Table 2 of the results). Of course, this could be extended to cover a larger set of randomly selected candidate decision vectors although there would be a computational trade-off. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d2b07a",
   "metadata": {},
   "source": [
    "#### More Comments and questions\n",
    "\n",
    "Thank you for pointing out all the typos, we have since corrected and heavily adjusted the readability of the paper including all cut-off sentences and general grammar mistakes. \n",
    "\n",
    "-> Notation Confusion\n",
    " \n",
    " $\\mathbf{X}$ is a set of variables and $\\mathbf{x}$ is a vector\n",
    "\n",
    "-> Arguments of $f$\n",
    "\n",
    "The features in the set $\\mathbf{X}_{S}$ take the corresponding value from the vector $\\mathbf{x}, \\mathbf{x}_{S}$. The features not in the set $\\mathbf{X}_{S}$, $\\mathbf{X}_{\\bar{S}}$ take on the ''missing'' feature value specified by the value function. For $v_{marg}$, each feature in $X_{\\bar{S}}$ takes its expected value. $v(\\mathbf{X}_{\\varnothing})$ indicates that all features should take on their ''missing'' feature value, which is $E[\\mathbf{X}]$ for the marginal value function. \n",
    "\n",
    "->Why On-manifold value functions:\n",
    "\n",
    "This is covered in lines 55:67 c2 in the paper and widely acknowloedged as the limitations of \"off-manifold value functions\" in the literature. \n",
    "\n",
    "-> Expectation Meaning\n",
    " \n",
    " Corrected to E[X2] = E[X3] = 0\n",
    "\n",
    "->Why Equal Feature Attribution \n",
    "\n",
    "We include the following to make this more explicit, $E[X2] = E[X3] = E[X1] = 0$ , $x = (1,1,1)$\n",
    "Now, given that the features are all independent with the same reference values and given the instance $x=(1,1,1)$, the Shapley value would give each of these features equal attribution of 1 given that $f(x) = 3$.\n",
    "\n",
    "-> Use Cases\n",
    "\n",
    "Use cases of this method would be any attribution challenge where we would usually apply the Shapley value. \n",
    "we motivate the use of Shapley Sets on high dimensional feature sets (such as time series) in section as a use case where it is not only useful to ascertain the importance of the features but also how and where these features interact in both the model and in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b36112",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
